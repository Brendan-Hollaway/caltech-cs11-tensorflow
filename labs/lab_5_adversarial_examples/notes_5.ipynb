{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Adversarial Examples and Special Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced optimizers\n",
    "SGD with momentum is a fairly good optimizer, but assumes that every parameter it's updating should have the same learning rate (and that the learning rate should stay the same over time).\n",
    "But, if a parameter contributes to a unit that activates often, it will more frequently receive strong gradient updates, and so have a higher \"effective learning rate\".\n",
    "Having parameters with very different \"effective learning rates\" slows down learning, since some \n",
    "\n",
    "Several advanced \"adaptive\" optimizers have been developed to deal with this problem.\n",
    "They have the additional advantage of working well with a broader range of learning rates than SGD, so they take less tuning.\n",
    "They're particularly effective when you expect certain features to be rare or sparse, since this is when differences in effective learning rate appear.\n",
    "\n",
    "I'll only describe the basics of these algorithms here.\n",
    "If you're interested in reading more, check out [this post on ruder.io](http://ruder.io/optimizing-gradient-descent/index.html).\n",
    "The [Keras documentation on optimizers](https://keras.io/optimizers/) also has some good info.\n",
    "\n",
    "### Adagrad\n",
    "Adagrad is an adaptive variant of SGD that divides the learning rate applied to a given parameter by the square root of the running total of gradient updates that parameter has _ever_ seen.\n",
    "As training progresses, the learning rate of each parameter monotonically decreases as it experiences more gradient updates, and the parameters that are updated the most see the sharpest decrease.\n",
    "\n",
    "Adagrad has the very appealing property that you basically don't need to tune the learning rate; the Keras documentation recommends leaving it fixed at 0.01.\n",
    "But this robustness comes with a major downside: the \"running total of past gradients\" it keeps track of per-parameter strictly grows, so eventually the learning rate becomes very small.\n",
    "\n",
    "This makes Adagrad a bad choice for long-running training tasks.\n",
    "Qualitatively, I don't see Adagrad used very often.\n",
    "\n",
    "To use Adagrad in TensorFlow, use [`tf.train.AdagradOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer).\n",
    "\n",
    "### RMSProp and Adadelta\n",
    "Instead of reducing the learning rate for a parameter based on all of the updates it's ever gotten, RMSProp and Adadelta use an exponential moving average of previous gradients, so the reduction is based on only the previous few updates. \n",
    "This prevents Adagrad's problem of monotonically-decreasing gradients, but does make it more sensitive to learning rate tuning. \n",
    "\n",
    "Of the two, RMSProp seems to be more popular, though there's not a lot of difference.\n",
    "RMSProp in particular is a very commonly-used optimizer.\n",
    "\n",
    "To use them, see [`tf.train.RMSPropOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer) and [`tf.train.AdadeltaOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer).\n",
    "\n",
    "### Adam\n",
    "Adam is a modification of RMSProp with an extra term similar to momentum (using a moving average of past gradients instead of the current gradient).\n",
    "It's extremely popular, and usually trains your model the fastest with the least tuning.\n",
    "\n",
    "To use it, see [`tf.train.AdamOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer).\n",
    "\n",
    "### Simple SGD generalizes better?\n",
    "Adaptive methods like Adam almost always converge faster much faster, but there is [some evidence that SGD + momentum](http://ruder.io/deep-learning-optimization-2017/index.html#improvingadam) generalizes better.\n",
    "Generally I stick to Adam, but when you need to squeeze accuracy out of a model (e.g. Kaggle) consider SGD + momentum instead of an adaptive method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow control in TensorFlow\n",
    "Generally, it's best to design a TensorFlow graph so that data always flows through the same branch in the same way.\n",
    "Ideally, each tensor represents exactly one thing.\n",
    "Because of this, flow control in TensorFlow is pretty awkward.\n",
    "But there are some cases where, even in graph programming, it's helpful to have conditionals and looping.\n",
    "\n",
    "### `tf.cond` \n",
    "[`tf.cond`](https://www.tensorflow.org/api_docs/python/tf/cond) is the closest thing TensorFlow has to an if-statement.\n",
    "It takes a scalar (\"falsy\" values like False and 0 map to False, everything else maps to True) and two _functions that return tensors_. \n",
    "Both functions must have the same number and type of outputs.\n",
    "\n",
    "Its behavior is counterintuitive.\n",
    "Both \"branches\" are functions (usually lambdas) that return tensors, and every \"upstream\" tensor that _either_ branch depends on is evaluated.\n",
    "Also, both functions get called exactly once, when `tf.cond()` is called, and after that their returned tensors are used instead.\n",
    "\n",
    "`tf.cond` is useful when part of the graph can take one of multiple similar inputs in different cases.\n",
    "An example is the assignment, where we use `tf.cond` to switch between an image and that image with added noise.\n",
    "\n",
    "The syntax is best understood with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True branch: result = 1.0\n",
      "False branch: result = 2.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1.0)\n",
    "b = tf.constant(2.0)\n",
    "switch = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "# This is one way to pass a tensor to `tf.cond`\n",
    "def a_fn():\n",
    "    return a\n",
    "\n",
    "result = tf.cond(switch, \n",
    "                 a_fn, \n",
    "                 lambda: b) # Lambdas are the more common way to pass tensors to cond\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('True branch: result =', sess.run(result, feed_dict={switch: True}))\n",
    "    print('False branch: result =', sess.run(result, feed_dict={switch: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.while_loop`\n",
    "[`tf.while_loop`](https://www.tensorflow.org/api_docs/python/tf/while_loop) updates a fixed list of tensors, called `loop_vars`, by calling a body function until a condition function is no longer true.\n",
    "\n",
    "`tf.while_loop` is useful for:\n",
    " - Updating values until they meet some condition\n",
    " - Running the same (side-effect-ful) operation many times\n",
    "\n",
    "Again, an example (taken from the documentation) is helpful to understand the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "i = tf.constant(0)\n",
    "\n",
    "def condition(i):\n",
    "    return tf.less(i, 10)  # Note: this is a tensor\n",
    "    \n",
    "def body(i):\n",
    "    return tf.add(i, 1)    # Note: this is also a tensor\n",
    "\n",
    "result = tf.while_loop(cond=condition, \n",
    "                       body=body, \n",
    "                       loop_vars=[i])  # The variables that get updated\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling gradient flow in TensorFlow\n",
    "The way we've used optimizers so far, they just modify every variable in the graph every time they perform a gradient update.\n",
    "For more complicated models (e.g. with multiple training phases), that behavior might not be desirable.\n",
    "So, TensorFlow provides a number of ways to control how gradients flow backwards through the graph and which variables are updated.\n",
    "\n",
    "#### [`tf.stop_gradient`](https://www.tensorflow.org/api_docs/python/tf/stop_gradient)\n",
    "If `a` is a tensor, then `tf.stop_gradient(a)` is that same tensor, except that _gradients will not flow backwards through this operation_.\n",
    "\n",
    "Recall from the discussion of backpropagation how the gradient applied to a parameter is the sum of gradients along all paths from that parameter to the output.\n",
    "If there is a `stop_gradient` operation on one of those paths, that path is removed from the computation.\n",
    "\n",
    "#### Passing variables to [`minimize()`](https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#minimize)\n",
    "When calling the `minimize()` function of an optimizer, you can optionally specify `var_list`, a list of variables to be changed when that operation is evaluated.\n",
    "If `var_list` is None, then every variable will be changed.\n",
    "\n",
    "#### [Manually modifying gradients](https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#processing_gradients_before_applying_them)\n",
    "We saw before that an optimizer's `compute_gradients()` and `apply_gradients()` functions allow us access the gradients directly.\n",
    "If you remove gradients and variables from the list returned by `compute_gradients()` before passing it to `apply_gradients()`, those variables will not be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras functional API\n",
    "The Keras sequential API works for models that take a single input and produce a single output by applying one layer at a time to that input.\n",
    "More sophisticated models, though, might:\n",
    " - Have more than one input or output\n",
    " - Use the output of a single layer in multiple places\n",
    " - Share the weights of a single layer in multiple places\n",
    " - Take an existing model and adds layers to it\n",
    "To do any of these things with Keras, you need the functional API.\n",
    "\n",
    "The best resource for learning the Keras functional API is [the official guide](https://keras.io/getting-started/functional-api-guide/), but the essence is:\n",
    " - Layers are functions, not objects\n",
    " - When a layer is called on a tensor, it returns a tensor\n",
    " - A `Model` object takes an input tensor and an output tensor and learns (using its interior layers and data) to predict the output tensor from the input tensor\n",
    " \n",
    "The Keras functional API seems to me to be the library that mimics how I think about differentiable programming most closely, so it's my favorite way of writing models.\n",
    "For many kinds of advanced models, it's probably the fastest.\n",
    "\n",
    "For a full worked example with the functional API, see the bottom of these notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras backend\n",
    "Keras is designed to work with multiple backends, with TensorFlow having the most support. \n",
    "Keras' `backend` module is a huge set of wrapper functions that (for the most part) call equivalents in whatever backend you're using and handle things like backpropagation and updating variables.\n",
    "\n",
    "If you're writing a model where Keras provides most, but not all, of the functionality, a good solution can be making custom layers and loss functions (using the Keras backend) rather than switching to TensorFlow.\n",
    "Keras layers are implemented as classes, which specify:\n",
    " - How their output shape depends on their input shape\n",
    " - What variables (\"weights\") they have\n",
    " - How they create output from input, as a small dataflow graph written using the Keras baackend\n",
    " \n",
    "\n",
    "Keras has an [official guide on writing layers](https://keras.io/layers/writing-your-own-keras-layers/), which you should read if you're interested.\n",
    "The [source code for built-in layers](https://github.com/keras-team/keras/tree/master/keras/layers) is also a good example of how to do this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial examples\n",
    "![adversarial panda](https://blog.openai.com/content/images/2017/02/adversarial_img_1.png)\n",
    "(Image source: [OpenAI post on adversarial example research](https://blog.openai.com/adversarial-example-research/))\n",
    "\n",
    "An \"adversarial example\" is an input that seems close to \"normal\" but has added \"adversarial noise\" designed specifically to trick a model.\n",
    "Adversarial noise is \"trained\" through gradient descent, given the weights of a particular model.\n",
    "\n",
    "It's derived from a simple observation.\n",
    "Traditionally (within a single batch) we hold the image input to a model fixed, and change the parameters of the model to minimize some quantity.\n",
    "But, our whole model is differentiable, so there's nothing stopping us from instead holding the weights of the model constant and changing the input image -- backpropagation lets us compute the gradient of the loss with respect to every pixel of the input.\n",
    "Adversarial noise is trained by using this trick to change the input image to _maximize_ the loss while holding the network weights fixed.\n",
    "The noise is kept small (either with clipping or regularization) to ensure that the input still looks, to the human eye, pretty much how it should.\n",
    "\n",
    "Properties of adversarial examples, and how to defend against them, are a [topic of current research](https://blog.openai.com/adversarial-example-research/).\n",
    "In general, we don't know how to stop adversarial attacks on neural networks.\n",
    "\n",
    "It might seem like, given the description above, that you need all of the weights of a model downloaded to create adversarial examples for it.\n",
    "But, as you'll find out in this week's assignment, it's actually sufficient to just be able to provide the model input and see output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: adversarial examples with the Keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
