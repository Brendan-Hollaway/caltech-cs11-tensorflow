{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: A Black-Box Adversarial Attack\n",
    "In this lab, we'll carry out an adversarial attack on a network trained on last week's dataset.\n",
    "The end result should be an image which looks close to some image in the dataset, but tricks the network into assigning high confidence to some other class.\n",
    "And, we'll do it black-box: without even having access to the network's weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Load the data\n",
    "This uses the same dataset as last time, so just copy the data over here in the same format.\n",
    "The same data loading and preprocessing as before is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed numpy rng for reproducibility\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Load data\n",
    "x_all = np.load('data/X.npy')\n",
    "y_all = np.load('data/Y.npy')\n",
    "\n",
    "# Maps dataset-provided label to true label\n",
    "label_map = {0:9, 1:0, 2:7, 3:6, 4:1, 5:8, 6:4, 7:3, 8:2, 9:5}\n",
    "\n",
    "# Correct dataset labels\n",
    "for row in range(y_all.shape[0]):\n",
    "    dataset_label = np.where(y_all[row])[0][0]\n",
    "    y_all[row, :] = np.zeros(10)\n",
    "    y_all[row, label_map[dataset_label]] = 1\n",
    "    \n",
    "# Shuffle features and targets together\n",
    "# Credit for this technique to:\n",
    "# https://stackoverflow.com/questions/4601373/\n",
    "# better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(x_all)\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(y_all)\n",
    "\n",
    "# Add a dummy channel axis to input images\n",
    "x_all = np.expand_dims(x_all, axis=-1)\n",
    "\n",
    "# Center and rescale data to the range [-1, 1]\n",
    "x_all = x_all - 0.5\n",
    "x_all = x_all * 2\n",
    "\n",
    "# Create a validation set from 30% of the available data\n",
    "n_points = x_all.shape[0]\n",
    "n_test = int(n_points * 0.3)\n",
    "n_train = n_points - n_test\n",
    "x_train, x_test = np.split(x_all, [n_train], axis=0)\n",
    "y_train, y_test = np.split(y_all, [n_train], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Train the black-box model\n",
    "Below, I've written a CNN in Keras to classify images from the dataset, and the code to train it.\n",
    "This will act as the \"black box model.\"\n",
    "\n",
    "Train the model using the code below.\n",
    "It should hit about 05-96% validation accuracy on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPool2D\n",
    "\n",
    "inputs = Input(shape=(64, 64, 1))\n",
    "layer = Conv2D(16, 5, strides=(2, 2), activation='relu')(inputs)\n",
    "layer = Conv2D(16, 3, activation='relu')(layer)\n",
    "layer = MaxPool2D()(layer)\n",
    "\n",
    "layer = Conv2D(32, 3, activation='relu')(layer)\n",
    "layer = Conv2D(32, 3, activation='relu')(layer)\n",
    "layer = MaxPool2D()(layer)\n",
    "\n",
    "layer = Conv2D(64, 3, padding='same', activation='relu')(layer)\n",
    "layer = Conv2D(64, 3, padding='same', activation='relu')(layer)\n",
    "layer = MaxPool2D()(layer)\n",
    "\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(128, activation='relu')(layer)\n",
    "probs = Dense(10, activation='softmax')(layer)\n",
    "\n",
    "target_model = Model(inputs, probs)\n",
    "target_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(1e-3)\n",
    "target_model.compile(opt, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.fit(x_train, y_train, \n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Build an \"oracle dataset\" and data pipeline\n",
    "Now, we'll treat the target model as a black box: pretend we don't have access to its weights or its original input data.\n",
    "In the wild, all we can do is give it inputs and see its outputs.\n",
    "\n",
    "We want to train a surrogate model to act similarly to the target model, so create a fake \"oracle dataset\" where the features are `x_all` and the outputs are the 10-vectors of probability the target model predicts for that input.\n",
    "\n",
    "Then, set up any `tf.data.Dataset` and `tf.data.Iterator` objects you need.\n",
    "In this case we don't have a test set, just a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Build a surrogate model\n",
    "The surrogate model is designed to act similarly to the target model, so that adversarial examples we create for it will also work on the target model.\n",
    "Feel free to use any architecture you want, but matching the target architecture closely (or exactly) is a good bet.\n",
    "\n",
    "Copy code from last week's assignment liberally.\n",
    "Most likely, you won't have to write all that much new code in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Input tensors\n",
    "Get a tensor for the input image and another for the correct label.\n",
    "Note that the label is already one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Adversarial noise\n",
    "This is the only part of the model that really differs from last week, and it's a bit tricky.\n",
    "\n",
    "Add a variable to the graph that represents the adversarial noise we'll add to one example.\n",
    "It should be the shape of a single input image and initialized to zeros.\n",
    "In addition, pass (to `get_variable`) the keyword argument `constraint=lambda x: tf.clip_by_value(x, -0.3, 0.3)`.\n",
    "Every time the variable is updated, it will become the result of the lambda function, which in this case constrains its pixel values to be in the range -0.3 to 0.3.\n",
    "(Equivalently, at every step we re-project the adversarial noise back into a hypercube at the origin with side length 0.6).\n",
    "I found that 0.3 works well, but feel free to change this value -- smaller values will produce less obvious noise, while larger values will produce more successful attacks. \n",
    "\n",
    "Add a boolean `tf.placeholder_with_default()` (default False) named \"use_noise\" to the graph.\n",
    "This will act as a \"switch\" controlling whether a given run uses adversarial noise.\n",
    "\n",
    "Add a `tf.cond()` operation that, depending on \"use_noise\", switches between the input image and the image plus the adversarial noise.\n",
    "This allows us to train the surrogate model without adversarial noise, then enable it when crafting the adversarial example.\n",
    "\n",
    "Finally, add a summary histogram and a summary image for the adversarial noise tensor, so we can plot it as we're learning the adversarial example.\n",
    "Also add a summary image for the output of `cond`, which will be our adversarial example later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: The rest of the model\n",
    "Using the functions `make_dense_layer()` and `make_conv_layer()` you wrote last week, finish the graph of the surrogate model.\n",
    "The only difference is that instead of using the input image, you should use the output of the `cond()` switch before, to allow adding adversarial noise.\n",
    "Don't add the optimizer yet.\n",
    "\n",
    "This should involve tensors that:\n",
    " - Act as hidden convolutional and dense layers\n",
    " - Compute the logits and probabilities for a batch of input images\n",
    " - Compute the predicted digit from the probabilities\n",
    " - Compute the mean cross-entropy loss over a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Surrogate optimizer\n",
    "Add an optimizer and update operation we'll use to train the surrogate model to act like the target model.\n",
    "It should just minimize the cross-entropy loss between the model's predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Adversarial loss\n",
    "When training the surrogate model, we want to change the model parameters to minimize the loss.\n",
    "When creating the adversarial example, we want to do something very different: _change the adversarial noise tensor alone to maximize the loss_.\n",
    "\n",
    "So, define a new adversarial loss which is the negative of the original loss, and a new optimizer to minimize it.\n",
    "When you call `minimize()`, pass in the keyword argument `var_list=[noise]`, where \"noise\" is the name of your adversarial noise tensor.\n",
    "This will prevent the optimizer from changing the weights of the model when we optimize the adversarial noise.\n",
    "\n",
    "Finally, add a summary scalar to plot the adversarial loss decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Train the surrogate model\n",
    "Train your surrogate model until it hits high accuracy.\n",
    "At the very least it should have 90% accuracy -- I hit 98-100% on the training set.\n",
    "Overfitting isn't really a concern here since we are actually trying to memorize the target model.\n",
    "\n",
    "When the training loop is done, save the model under `./checkpoints/model_surrogate.ckpt`.\n",
    "We won't be modifying this particular checkpoint any more, it'll contain the fully-trained surrogate model with zero adversarial noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Learn the adversarial example\n",
    "Finally, it's time to create an adversarial example using our surrogate model.\n",
    "Pick an image from the test set (or use the one I picked below), then run a training loop to minimize the adversarial loss (equivalently, maximize the model loss on that example).\n",
    "To do this, use `sess.run(..., feed_dict={pixels: [img], label: [lbl], use_noise: True})`.\n",
    "This turns on the `use_noise` switch we set before, and overwrites the input image with the image we're going to turn into an adversarial example.\n",
    "\n",
    "At the start, load the checkpoint we saved before.\n",
    "When it's done, save it to a new checkpoint, `./checkpoints/model_adversarial.ckpt`.\n",
    "This new checkpoint should have exactly the same model parameters as before (remember that we're only optimizing the noise), but a nonzero noise tensor.\n",
    "\n",
    "At the end, also save the adversarial example (which will be contained in the result of your `cond`) and the noise tensor to a numpy array so we can use them later.\n",
    "\n",
    "Periodically write the image and histogram summaries so you can look at them in TensorBoard later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick and plot the image we'll turn into an adversarial example\n",
    "idx = 1\n",
    "img = x_test[idx]\n",
    "lbl = y_test[idx]\n",
    "\n",
    "plt.imshow(img[:, :, 0], cmap='gray')\n",
    "plt.title('True label: {}'.format(np.argmax(lbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Visualize the adversarial example\n",
    "Plot the original example, the adversarial example, and the adversarial noise below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Demonstrate that the surrogate model fails on the adversarial example\n",
    "Compute the surrogate model's prediction and probability for the original example and the adversarial example, and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Demonstrate that the target model fails on the adversarial example\n",
    "This is the real test -- transferring the learned adversarial example from the surrogate model to the target model.\n",
    "Compute the target model's prediction and probability for the original example and the adversarial example, and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you've carried out a black-box adversarial attack!\n",
    "These kinds of adversarial attacks are a serious concern in the real world, since they can be [made to work when printed on paper](https://blog.openai.com/robust-adversarial-inputs/) and [we're still bad at defending against them](https://blog.openai.com/adversarial-example-research/).\n",
    "\n",
    "Some interesting things to try:\n",
    " - Did the surrogate model and the target model misclassify the adversarial example in the same way? (Mine did)\n",
    " - How subtle can you make the noise while still tricking the target network?\n",
    " - Look at how the adversarial example evolves through training in TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
