{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning: classification and regression\n",
    "For now, we'll stick to supervised learning: the case of machine learning where we want to learn a function from input features $\\vec{x}$ to some output $y$, for which we have a dataset of many examples of inputs and their associated \"true\" outputs $\\{\\vec{x}_i, y_i\\}$.\n",
    "\n",
    "Simple supervised learning problems are split into two cases.\n",
    "**Regression** is the case where each $y_i$ is continuous, a real-valued number, and **classification** is the case where $y_i$ is discrete, one of a few classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "The loss function maps from the parameters $\\theta$ of a model, and the set of examples (features and their true labels, $\\{\\vec{x_i}, y_i\\}_i$), to a single value that represents how badly the model fits the data.\n",
    "Minimizing the loss function is equivalent to finding the \"optimum\" parameter settings, in the sense that if our model was generating the data, it is the model with these parameters that is most likely to have generated the data (instead of a model structured the same way with any other parameters).\n",
    "\n",
    "We can justify this kind of inversion using Bayes' theorem:\n",
    "$$\n",
    "p(\\vec{\\theta} | \\text{data}) = \\frac{p(\\text{data} | \\vec{\\theta}) \\cdot p(\\vec{\\theta})}{p(\\text{data})} \\propto p(\\text{data} | \\vec{\\theta})\n",
    "$$\n",
    "Therefore maximizing the probability that our model was the one that generated the data is equivalent to finding the most probable parameters given the data, which is exactly what we want to do.\n",
    "We can also compute the loss value on held-out values (a validation set) to see how well the model generalizes to unseen data.\n",
    "\n",
    "To make learning feasible, we usually assume that the loss function is possible to express as an average of per-example loss functions:\n",
    "$$ L_\\text{total}(\\{\\vec{x_i}, y_i\\}_i^n, \\vec{\\theta}) = \\frac{1}{n} \\sum_i^n L((\\vec{x}_i, y_i), \\vec{\\theta}) $$\n",
    "\n",
    "Often the loss over the entire dataset is called a \"cost function\" and the loss over individual examples is just called a \"loss function,\" so I'll use that notation from now on.\n",
    "Either way, it's important that the loss function is differentiable so we can minimize it with gradient descent.\n",
    "\n",
    "### Squared error\n",
    "The (mean) squared error (MSE) is the \"default\" loss function for regression:\n",
    "$$ L(y, \\hat{y}) = (y - \\hat{y})^2 $$\n",
    "where $y$ is the true value to be predicted, and $\\hat{y}$ is the model's prediction.\n",
    "\n",
    "It penalizes the model for mistakes super-linearly, giving larger weight to big mistakes than small ones.\n",
    "This can make MSE vulnerable to outliers.\n",
    "\n",
    "### Cross-entropy\n",
    "Cross-entropy loss (or \"log loss\") is the most common loss function for classification.\n",
    "\n",
    "The output of a classification model is a vector of probabilities, one per class, that should sum up to one.\n",
    "The $i$th probability represents how confident the model is that the input corresponds to class $i$.\n",
    "In an information-theoretic sense, cross-entropy loss measures how different the probability distribution given by the model is from the empirically-measured distribution for that one example (0 probability for every class except the true one, which has probability 1).\n",
    "\n",
    "As the model's confidence in the correct class approaches 1, the cross-entropy loss approaches 0.\n",
    "As the model's confidence in the correct class approaches 0, the cross-entropy loss increases to infinity.\n",
    "\n",
    "#### The binary case\n",
    "In binary classification, your model outputs a single probability $p(x)$: the probability that the output label is 1 (which is one minus the probability that the label is 0).\n",
    "The true label $y$ is 0 or 1, and the loss is\n",
    "$$L(\\vec{x}, y; \\vec{\\theta}) = - y \\cdot \\log (p) - (1 - y) \\cdot \\log (1 - p)\n",
    "= \\begin{cases} -\\log(p), & \\text{if } y = 0 \\\\ -\\log(1-p), & \\text{if } y = 1 \\end{cases}\n",
    "$$\n",
    "\n",
    "#### The multi-class case\n",
    "In multi-class classification (with multinomial cross-entropy loss), we turn the true label into a \"one-hot encoding\" -- a vector with one entry per possible class, that's zero everywhere except the true class.\n",
    "For example, for a problem with $n=4$ classes and an example with correct label of 1, the one-hot encoding is \n",
    "$$p_\\text{true}(y) = \\begin{bmatrix}0 & 1 & 0 & 0 \\end{bmatrix}$$\n",
    "which defines a discrete \"probability distribution\" over possible labels that just assigns probability 1 to the correct label.\n",
    "Our model outputs a vector of confidences, $p_\\text{model}(y)$.\n",
    "The loss is\n",
    "$$L = -\\sum_{i=0}^n p_\\text{true}(y_i) \\log (p_\\text{model}(y_i))\n",
    "= \\begin{cases} - \\log p_\\text{model}(y_i) & \\text{if } y = i \\\\ \\vdots \\end{cases}$$\n",
    "Often this is computed by taking the dot product of the one-hot encoded label vector with the probability vector, then taking the log.\n",
    "\n",
    "Note that this loss function only cares about what probability the model assigns to the correct class, not any of the other classes.\n",
    "This can make computing cross-entropy loss more efficient (i.e. by not computing the probabilities assigned to any other class).\n",
    "\n",
    "#### Aside: the other terms in the Bayes theorem derivation\n",
    "There are two terms we didn't talk about.\n",
    "$p(\\text{data})$ is the _probability of seeing the data we did under the true data generatng process_, commonly called the \"evidence\", and it generally doesn't impact our model-building. \n",
    "\n",
    "The other term, $p(\\theta)$ is much more interesting. \n",
    "It's our prior belief, represented as a probability distribution, about what kinds of parameters we expect to see.\n",
    "In machine learning, we almost always express our priors through how the model is structured, how we preprocess (or augment) the data, and what kind of regularization we use.\n",
    "Using neural networks (next week), for instance, expresses a strong prior that the function we want to learn is a _hierarchical composition of simple patterns_.\n",
    "\n",
    "#### Aside: other loss functions\n",
    "Lots of the time, other loss functions make sense to use.\n",
    "It's problem-dependent.\n",
    "For example, you might want to use dice-coefficient loss to deal with unbalanced classes in problems like classifying each pixel of an image (the \"semantic segmentation\" problem).\n",
    "MSE and cross-entropy are good default choices, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic and minibatch gradient descent\n",
    "Since the loss over the entire dataset decomposes into an average of per-example losses, we can approximate the total loss with an average over a smaller number of examples:\n",
    "$$L(\\{\\vec{x}_i, y_i\\}; \\vec{\\theta}) = \\frac{1}{n} \\sum_i^n L((\\vec{x}_i, y_i), \\vec{\\theta}) \\approx \\frac{1}{m} \\sum_i^m L((\\vec{x}_i, y_i), \\vec{\\theta})$$\n",
    "where $m$ is the \"batch size\", or the number of examples used to approximate the true dataset loss in this case.\n",
    "\n",
    "This is called \"minibatch gradient descent\" or \"stochastic gradient descent\" (SGD) (sometimes this term is restricted for $m=1$).\n",
    "It can converge faster than full-scale gradient descent because often small batches are sufficient to approximate the average loss reasonably well, and the average direction of steps taken in the direction opposite the gradient of the average minibatch loss is the same as if you were using the dataset loss.\n",
    "As a result, minibatch gradient descent is considered the best way to train most machine learning models.\n",
    "\n",
    "Some considerations when picking a batch size:\n",
    " - Smaller batches provide a less-accurate estimate of the direction to move parameters in at each step\n",
    " - Larger batches take a longer time to compute\n",
    " - [There is evidence that the noise introduced from small batches is beneficial for reaching optima that generalize out-of-sample (geometrically, \"broad\" minima instead of \"sharp\" ones)](https://arxiv.org/abs/1609.04836)\n",
    " - [In some sense lowering the learning rate and increasing the batch size have the same effect](https://arxiv.org/abs/1711.00489)\n",
    " - Large batch sizes compute faster per-example on GPUs, making training the model overall faster (by reducing the frequency with which the GPU and CPU need to swap memory)\n",
    " - Large batches may not fit on the available memory (eg video RAM in a GPU)\n",
    " - Power-of-two batch sizes compute faster on GPUs (because of how \"tensor cores\" work)\n",
    " \n",
    "Common batch sizes are anywhere from 4 to 64, sometimes higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Linear regression is the simplest model we'll cover.\n",
    "Linear regression of one variable involves as parameters a vector of weights $\\vec{w}$ and a scalar bias $b$; given a vector of input features $\\vec{x}$, the model predicts $\\hat{y} = \\vec{w}^T \\vec{x} + b$.\n",
    "The output variable is a linear combination of the inputs weighted by the weight vector, plus a bias that captures something like the mean output.\n",
    "\n",
    "While linear algebra gives us a closed-form solution, in practice it's ineffient with large datasets.\n",
    "Instead, learning $\\vec{w}$ and $b$ with gradient descent on mean-squared error produces the same optimum, since the learning problem for linear regression is convex.\n",
    "\n",
    "Linear regression can actually be used to regress against any handmade set of features computed from the data, so long as the output is expected to be a linear combination of the features.\n",
    "For instance, we can fit a quadratic polynomial by computing the square of every input feature, and treating them as completely new features: \n",
    "$$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & \\cdots \\end{bmatrix} \\rightarrow  \\begin{bmatrix} x_1 & x_2 & \\cdots & x_1^2 & x_2^2 & \\cdots \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Despite the name, logistic regression is the linear model for classification.\n",
    "Linear regression on the probability that a particular class is right doesn't make much sense, because:\n",
    " - Individual class probabilities must be in the range [0, 1] and linear regression may produce values outside of this range\n",
    " - All class probabilities must sum to 1\n",
    "\n",
    "Logistic regression models follow a few steps:\n",
    " 1. For each class, perform linear regression to an \"unnormalized probability\" for that class. This value is called the **logit**, and it corresponds to the natural log of the odds (as opposed to probability) that the class is correct. This linear regression makes sense, since the log-odds can take any value from $-\\infty$ to $\\infty$.\n",
    " 2. Convert the vector of log-odds to a valid probability distribution. In the one-variable case, this is done through the _logistic function_. In the multi-variable case, it means applying the _softmax function_.\n",
    " 3. Train the model (usually using cross-entropy loss) on the computed probability distribution over classes.\n",
    "\n",
    "#### One-variable case and the logistic function\n",
    "In the one-variable case, $y \\in \\{0, 1\\}$ and the model is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&l = \\vec{\\alpha}^T \\vec{x} + b & \\text{where $l$ is the logit, the log of the odds that $y=1$} \\\\\n",
    "&p = \\sigma(l) = \\frac{e^l}{e^l + 1} & \\text{where $\\sigma$ is the logistic function and $p$ is the model probability that $y = 1$} \\\\ \n",
    "&L = -y \\log(p) - (1 - y) \\log (1 - p) & \\text{where $L$ is the (cross-entropy) loss}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The logistic function converts from log-odds to probability by exponentiating the logit (to undo the log), then computing the ratio of the odds (numerator) to the total odds (denominator).\n",
    "![logistic function](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)\n",
    "Image credit: [Wikipedia article on logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "The logistic function...\n",
    " - Maps every input to the range \\[0, 1\\]\n",
    " - Is continuously increasing\n",
    " - \"Saturates\" (getting near-zero derivative) for high and low input values\n",
    " \n",
    "#### Multivariable case and the softmax function\n",
    "This can be generalized to the case of more than one variable.\n",
    "In this case, there is one logit value per class, $l_i$, and so there is one linear regression per class.\n",
    "Then the softmax function is applied, which converts the logits into probabilities:\n",
    "$$ p_i = \\frac{\\exp(l_i)}{\\sum_j \\exp(l_j)}$$\n",
    "It works exactly the same way as the logistic function, taking the ratio of the unnormalized probability of one class to the total of unnormalized probabilities.\n",
    "\n",
    "The probabilities computed by the softmax function...\n",
    " - Are each individually in the range \\[0, 1\\]\n",
    " - Together sum to 1\n",
    " - Increase monotonically with their associated logit\n",
    " \n",
    "Another interpretation of the softmax function is that it's a \"softened\" or \"smoothed\" version of the argmax function, which sets the largest element of a vector to 1 and all other elements to 0.\n",
    "The softmax function just makes the largest element near 1 and all of the other elements near 0 -- the fact that it's \"softened\" allows it to be differentiable, and so we can use it for gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation and the chain rule\n",
    "The backpropagation algorithm, and how it combines with gradient descent to make differentiable programming a powerful way of writing models, is probably the most important concept from this class.\n",
    "\n",
    "The critical idea is this: _if you have a computational graph made of only differentiable operations, you can efficiently compute the derivative of any one value with respect to every other value at once_.\n",
    "\n",
    "By using the [multivariate chain rule](https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions), we can easily (and automatically!) compute the derivative of a value with respect to a single other value, assuming the derivatives of each individual operation are known:\n",
    "![backpropagation on a computational graph](https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
    "In the above graph, all of the operations, values, and single-edge derivatives are labeled.\n",
    "To compute the partial derivative of one value $A$ with respect to another value $B$, traverse every possible path from $B$ to $A$; within a path, multiply each of the edge partial derivatives together, and at the end add up all of the path derivatives to get the _total derivative_.\n",
    "For instance, $\\frac{\\partial e}{\\partial b} = (\\frac{\\partial e}{\\partial c} \\times \\frac{\\partial c}{\\partial b}) + (\\frac{\\partial e}{\\partial d} \\times \\frac{\\partial d}{\\partial b}) = (1 \\times 2) + (1 \\times 3) = 5$.\n",
    "\n",
    "To understand this, **convince yourself** (really!) that:\n",
    " 1. The single-variable chain rule means that multiplying the partial derivatives along a single path to get the contribution of that path to the derivative of the output\n",
    " 2. The multi-variable chain rule means that we can add each of the paths from $b$ to $e$ to get its total contribution to the derivative\n",
    "\n",
    "This process of **automatic differentiation** (abusing terminology slightly) makes it possible to compute the derivative of a single value with respect to another single value by traversing each path once.\n",
    "\n",
    "However, if we want to compute the gradient of the loss function over a minibatch with respect to the parameters of our model (i.e. the `tf.Variable`s) so we can update them all with gradient descent, we need the partial derivative of the loss with respect to each parameter individually.\n",
    "Naively \"summing over paths\" means we might wind up computing the same value many times, making the algorithm inefficient.\n",
    "\n",
    "Instead, we step backwards through the graph, first computing the partial derivative with respect to the direct parents of the desired node ($\\frac{\\partial e}{\\partial c}$ and $\\frac{\\partial e}{\\partial d}$), then computing the partial derivative with respect to their parents, and so on.\n",
    "You will notice that each of these computations makes use of values we already have (namely, the partial derivatives computed further-along in the graph) and only a single new edge, multiplying the saved derivative by the newly-computed derivative on that edge.\n",
    "Thus, once we've computed the partial derivative of the loss with respect to every parameter, we have computed the derivative on each edge exactly once.\n",
    "\n",
    "You should think of _values flowing forwards through a network_ (and being saved, since they're needed for differentiation) and _derivatives flowing backwards_.\n",
    "Alternatively, this is a dynamic-programming solution to the problem of computing all of these derivatives, where we get a (worst-case) exponential-time speedup by computing the values in the correct order and caching them.\n",
    "Computing the gradient of a single value (the loss function) with respect to every value in the graph takes only time time to compute a _forwards pass_ (to compute the loss), plus the sum of the times it takes to compute the derivatives of every individual operation (the _backwards pass_).\n",
    "\n",
    "The end result is a beautiful system where so long as we can build a model out of differentiable operations, we can efficiently optimize it with gradient descent (subject, of course, to optimization's usual quibbles about smoothness assumptions, local minima, etc).\n",
    "This is what differentiable programming is all about!\n",
    "\n",
    "#### Outside reading on backpropagation\n",
    "Since this is a three unit class I can't require you to read these, but I can _promise_ they'll be worth your time, and that once you read all three you'll deeply understand one of the most important algorithms in the modern world:\n",
    " - [\"Calculus on Computational Graphs: Backpropagation\" (Chris Olah)](https://colah.github.io/posts/2015-08-Backprop/) quickly and intuitively derives backpropagation. If you only read one of these resources, make it this one.\n",
    " - [\"Hacker's guide to Neural Networks\" (Andrej Karpathy)](https://karpathy.github.io/neuralnets/) derives the chain rule and backpropagation from scratch, from the perspective of math as combining \"circuits\" (operations) and from a \"hacking\" or \"coding\" perspective\n",
    " \n",
    "[Image credit: Colah's Blog](https://colah.github.io/posts/2015-08-Backprop/)\n",
    "(Also, credit to the blog for examples I've taken here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "In this case, I can't give a better explanation than [the TensorFlow official guide](https://www.tensorflow.org/guide/datasets).\n",
    "Read the following sections:\n",
    " - [Basic mechanics (all subsections)](https://www.tensorflow.org/guide/datasets#basic_mechanics)\n",
    " - [Consuming NumPy arrays](https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays)\n",
    " - [Batching dataset elements](https://www.tensorflow.org/guide/datasets#batching_dataset_elements)\n",
    " - [Training workflows](https://www.tensorflow.org/guide/datasets#training_workflows)\n",
    " \n",
    "For this class, don't use feeding to input data ever (it's slow), and don't use `tf.train.MonitoredTrainingSession` (it's meant for distributing training over many machines).\n",
    "\n",
    "I prefer to use reinitializable iterators so I can do end-of-epoch processing and treat multiple datasets (e.g. training and validation) transparently with the same operations.\n",
    "But, how you structure your input pipeline is mostly up to you (and what makes sense for the problem).\n",
    "\n",
    "If you're interested in making performant data pipelines, check out the [official guide on data input pipeline performance](https://www.tensorflow.org/guide/performance/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and restoring variables\n",
    "When starting a new session, the values of variables are lost -- they must be initialized and trained again, or loaded from a file.\n",
    "To save all of the variables in a graph to a file, first create a `tf.train.Saver()`, then run `saver.save(sess, 'file_path')` where `sess` is a `tf.Session`.\n",
    "To restore the variables again, run `saver.restore(sess, 'file_path')`.\n",
    "\n",
    "Note that in this case, 'file_path' is actually a prefix to a number of checkpoint files.\n",
    "\n",
    "To learn more (saving and loading only specific variables, and the `SavedModel` abstraction for serving models), look at the [official guide](https://www.tensorflow.org/guide/saved_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "TensorBoard encapsulates all of the many visualization tools that come with TensorFlow.\n",
    "This week we'll cover two of its dashboards: Graphs (for visualizing the computational graph) and Scalars (for plotting values as sessions run).\n",
    "\n",
    "### Running TensorBoard\n",
    "When using TensorBoard, you first need at least one [`tf.summary.FileWriter`](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter) to create log files in some directory.\n",
    "Then, run `tensorboard --logdir=path` in your shell, where `path` is the path to the log directory (or a parent directory), and go to the URL `localhost:6006` in a browser.\n",
    "\n",
    "### Graph visualization\n",
    "To visualize a graph, either pass a `tf.Graph` to the `FileWriter` when creating it, or use its `add_graph()` method.\n",
    "If you want to see tensor shapes in the graph (which is really useful) you need to pass it in from `sess.graph`.\n",
    "This is one of the best ways to debug a model: make sure the right operations are connected and the shapes are correct.\n",
    "\n",
    "To expand grouped nodes (for instance, under a `name_scope`), double click the node.\n",
    "Nested name scopes can really make a graph a lot more readable.\n",
    "There are plenty of other options worth playing around with too, in the left sidebar.\n",
    "\n",
    "To collect metadata from a particular run and visualize it in the graph, first create a `tf.RunMetadata()` object, then pass it to `sess.run()`, and finally pass it to the `FileWriter`'s `add_run_metadata()` method.\n",
    "This lets you see things like exactly what fraction of compute time or memory was spent on which operations, which can help debug slow models.\n",
    "To see them, select the tag you'd saved the metadata under with the left bar under \"Session runs.\"\n",
    "Best combined with `tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)` passed to `run()`'s `options` argument.\n",
    "Don't do this for every run though.\n",
    "\n",
    "More detailed info in the [official guide on graph visualization](https://www.tensorflow.org/guide/graph_viz).\n",
    "\n",
    "### Plotting scalars\n",
    "Often there are scalars in your model worth keeping track of throughout training and inference.\n",
    "Obvious examples include loss and accuracy -- if loss is decreasing and accuracy is increasing, the model is training correctly.\n",
    "\n",
    "To keep track of a scalar, run `tf.summary.scalar('name', scalar_tensor)`, which returns a summary operation. \n",
    "Passing the operation to `sess.run()` returns a summary object, which you can pass to the `add_summary()` method (along with an index, like batch number) of a `FileWriter` to plot the scalar and make it visible on TensorBoard. \n",
    "However, doing this with all of the summaries is inconvenient, so `tf.summary.merge_all()` creates an operation that, when run, runs all of the summary operations you've defined and returns their summaries merged as a single object.\n",
    "\n",
    "Using multiple `FileWriter`s pointed at different directories, and pointing TensorBoard's `logdir` at a parent directory of both, lets you plot multiple runs at once.\n",
    "This is useful for plotting train and test statistics, or runs with different datasets or hyperparameters.\n",
    "\n",
    "More detailed info in the [official guide on summaries](https://www.tensorflow.org/guide/summaries_and_tensorboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: linear regression\n",
    "A concrete example of a problem worked end-to-end with TensorFlow should make this all a lot more concrete.\n",
    "This performs a linear regression on the Boston house-prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "I'm using a scipy default dataset for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT'] \n",
      "\n",
      "Input shape: (506, 2)\n",
      "Target shape: (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "dataset = load_boston()\n",
    "print('Feature names:', dataset.feature_names, '\\n')\n",
    "\n",
    "x_all = dataset.data\n",
    "y_all = dataset.target\n",
    "\n",
    "# Shuffle some features and targets together\n",
    "together = np.concatenate([x_all[:, [5, 12]], \n",
    "                           np.expand_dims(y_all, axis=1)], \n",
    "                          axis=1)\n",
    "np.random.shuffle(together)\n",
    "x_all = together[:, :-1]\n",
    "y_all = together[:, -1]\n",
    "\n",
    "print('Input shape:', x_all.shape)\n",
    "print('Target shape:', y_all.shape)\n",
    "\n",
    "# Split data into train and test sets\n",
    "n_points = x_all.shape[0]\n",
    "n_features = x_all.shape[1]\n",
    "n_train = int(n_points * 0.7)\n",
    "n_test = n_points - n_train\n",
    "\n",
    "x_train, x_test = np.split(x_all, [n_train], axis=0)\n",
    "y_train, y_test = np.split(y_all, [n_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 128\n",
    "n_batches_per_epoch_train = n_train // batch_size\n",
    "n_batches_per_epoch_test  = n_test  // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one dataset for training data and one for test data\n",
    "# Each dataset gets shuffled, batched, and cached in memory\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\\n",
    "    .shuffle(500).batch(batch_size).cache()\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\\n",
    "    .shuffle(500).batch(batch_size).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a reinitializable iterator so the model can work with both datasets\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    dataset_train.output_types, \n",
    "    dataset_train.output_shapes)\n",
    "\n",
    "# These operations initialize the iterator with one of the datasets\n",
    "train_init_op = iterator.make_initializer(dataset_train)\n",
    "test_init_op = iterator.make_initializer(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensors\n",
    "with tf.name_scope('inputs'):\n",
    "    next_elem = iterator.get_next()\n",
    "    features, target = next_elem # Shapes: (?, 13) and (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bias_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables: a weights vector (one weight per feature) initialized uniformly\n",
    "#            and a bias scalar, initialized to zero\n",
    "weights = tf.get_variable('weights', shape=(n_features), dtype=tf.float64,\n",
    "                          initializer=tf.glorot_uniform_initializer())\n",
    "bias = tf.get_variable('bias', shape=(), dtype=tf.float64,\n",
    "                       initializer=tf.zeros_initializer())\n",
    "\n",
    "# Track how bias changes throughout training by\n",
    "# adding a summary operation to the graph\n",
    "tf.summary.scalar('bias', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction\n",
    "with tf.name_scope('predicted_price'):\n",
    "    price = tf.reduce_sum(features * weights, axis=1) + bias # Shape: (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE loss\n",
    "with tf.name_scope('loss'):\n",
    "    mse_per_example = tf.pow(price - target, 2) # Shape: (?)\n",
    "    mse_batch = tf.reduce_mean(mse_per_example) # Shape: ()\n",
    "    \n",
    "    tf.summary.scalar('loss', mse_batch) # Add a loss summary operation to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an optimizer to the graph\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4)\n",
    "optimize_step = optimizer.minimize(mse_batch)\n",
    "\n",
    "# I use a low learning rate here because MSE can lead to \n",
    "# high loss values at the start of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Average test set loss: 870.1028330393826\n",
      "Epoch: 100\n",
      "Average test set loss: 99.58161025963925\n",
      "Epoch: 200\n",
      "Average test set loss: 47.676651728694125\n",
      "Epoch: 300\n",
      "Average test set loss: 39.731645083045485\n",
      "Epoch: 400\n",
      "Average test set loss: 34.98074597850494\n",
      "Epoch: 500\n",
      "Average test set loss: 32.392231539514896\n",
      "Epoch: 600\n",
      "Average test set loss: 26.154046231504786\n",
      "Epoch: 700\n",
      "Average test set loss: 24.131216298191575\n",
      "Epoch: 800\n",
      "Average test set loss: 28.145186965708184\n",
      "Epoch: 900\n",
      "Average test set loss: 25.993781945465507\n"
     ]
    }
   ],
   "source": [
    "# Training code\n",
    "saver = tf.train.Saver() # Save varibles\n",
    "merged_summaries = tf.summary.merge_all() # Single merged summary op\n",
    "\n",
    "train_batch = 0\n",
    "test_batch = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Make one writer for training logs and another for test logs \n",
    "    train_writer = tf.summary.FileWriter('./logs_lecture/train', graph=sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('./logs_lecture/test')\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        # Load training data\n",
    "        sess.run(train_init_op)\n",
    "        \n",
    "        # Iterate over the dataset once\n",
    "        while True:\n",
    "            try:\n",
    "                if train_batch > 0: # Typical batch\n",
    "                    # Run summary ops and optimization\n",
    "                    summary, _ = sess.run([merged_summaries, optimize_step])\n",
    "                    train_writer.add_summary(summary, train_batch)\n",
    "                    train_batch += 1\n",
    "                else:\n",
    "                    # On the first batch, run a full trace\n",
    "                    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                    run_metadata = tf.RunMetadata()\n",
    "                    \n",
    "                    summary, _ = sess.run([merged_summaries, optimize_step],\n",
    "                                          options=run_options,\n",
    "                                          run_metadata=run_metadata)\n",
    "                    \n",
    "                    train_writer.add_summary(summary, train_batch)    \n",
    "                    train_writer.add_run_metadata(run_metadata, \n",
    "                                                  'first training batch')\n",
    "                    train_batch += 1\n",
    "            except tf.errors.OutOfRangeError: # No more data\n",
    "                break\n",
    "    \n",
    "        # Validation on every hundredth epoch, and the last epoch\n",
    "        if epoch % 100 != 0 or epoch == n_epochs - 1:\n",
    "            continue\n",
    "\n",
    "        print('Epoch:', epoch)\n",
    "        sess.run(test_init_op)\n",
    "        losses = [] # Track average loss over test set\n",
    "        while True:\n",
    "            try:\n",
    "                summary, loss = sess.run([merged_summaries, mse_batch])\n",
    "                losses.append(loss)\n",
    "\n",
    "                # Roughly align test batches with training batches\n",
    "                test_writer.add_summary(summary, test_batch)\n",
    "                test_batch += 10\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        average_loss = np.mean(losses)\n",
    "        print('Average test set loss:', average_loss)\n",
    "        \n",
    "    # Save model\n",
    "    saver.save(sess, './checkpoints_lecture/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints_lecture/model.ckpt\n",
      "[23.59048563 11.58999484 23.67243491 31.78673974 21.08771867 21.40276478\n",
      " 20.01463    27.8287872  22.8079451  20.63216073 19.11799765 18.7270927\n",
      " 16.82795354 18.53721964 20.43305723 28.50040388 10.20423139 19.77046986\n",
      " 18.99328917 27.24831591 30.26542725 26.7187626  13.07550166 27.78870605\n",
      " 25.44393567 20.58965489 21.07965916 25.34515203 26.37827784 23.8050794\n",
      " 12.65099928  4.85891796 19.0345655  30.33503147 16.32533182 26.91917844\n",
      " 25.11483252 19.72071274 22.33801071 23.84616095 29.59723826 34.80842432\n",
      "  7.71076241 31.18955762 24.84628003 22.43852535 21.73426463  9.91208842\n",
      "  5.74412803 35.17984748 25.09500072 18.06656098 31.10896135 21.63767657\n",
      " 20.87063267 23.75355433 23.37208355 20.81788443 17.06854083 28.72053063\n",
      " 13.46501665 29.84361822 20.66316033 16.60590474 12.25418337 38.06346915\n",
      " 21.46080157 22.63572731 26.70726009 30.49097875 35.72997851 23.62114529\n",
      "  5.82986658 28.27430126 15.26609272 36.72743483  5.22045769 16.95038996\n",
      " 18.75612322 35.16903865 36.22368286 28.69816332 37.07423653 20.23072195\n",
      " 24.30793024 29.76415854 10.358076   21.56936304 23.59198753 17.64826621\n",
      " 30.5002118  31.62021275 18.97387491 26.14715271 27.44397269 25.83524921\n",
      " 29.72434979 20.24827795 27.17950723 22.09930965 29.293701   32.70229006\n",
      " 29.07288058 16.89968841 20.71043418 30.70967486 27.49124654 22.65728639\n",
      " 26.0111365  25.39008517 18.85768416 15.8519798  18.354146   21.44444074\n",
      " 13.63524373 30.28380678 26.6765049  14.49616965 17.1530816  25.12052332\n",
      " 21.12454005 29.09397249 23.27493802 26.23461332 36.60234835 31.88415767\n",
      " 26.09960011 28.73642055]\n"
     ]
    }
   ],
   "source": [
    "# Look at some test-set predictions\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './checkpoints_lecture/model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    print(sess.run(price))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
